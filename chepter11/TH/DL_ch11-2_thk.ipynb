{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11장\n",
    "### 11.4\n",
    "----\n",
    "\n",
    "### Optimizer, Activation, Initializer를 조합하여 모델을 만들고 평가해 봅니다.\n",
    "\n",
    "* 수렴이 언제부터 시작되나요? \n",
    "\n",
    "* 모델의 성능은 어떤가요?\n",
    "\n",
    "* 전체 훈련 속도는 몇인가요? \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_image(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    #plt.title(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 0 ] 데이터셋 준비\n",
    "\n",
    "* MNIST 데이터셋을 불러오세요. tf.keras.datasets.mnist.load_ data()를 사용하여 데이터를 적재할 수 있습니다.\n",
    "* 데이터셋의 차원을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Load\n",
      "Train set:  (60000, 28, 28) [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "Test set:  (10000, 28, 28) [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59\n",
      "  21 236 254 106   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "(img, y_train), (img_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print('* Load')\n",
    "print('Train set: ', img.shape, img[0][10])\n",
    "print('Test set: ', img_test.shape, img_test[0][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_image(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 불러온 이미지을 **preProcessing** 함수를 통해 데이터셋으로 전환합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img, img_test):\n",
    "\n",
    "    # reshape\n",
    "    print('* Reshape')\n",
    "    x_train = np.reshape(img, (img.shape[0],img.shape[1]*img.shape[2]*1))\n",
    "    x_test = np.reshape(img_test, (img_test.shape[0], img_test.shape[1]*img_test.shape[2]*1))\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    # Normalize\n",
    "    print('* Normailze')\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Reshape\n",
      "(60000, 784)\n",
      "(10000, 784)\n",
      "* Normailze\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = preProcessing(img, img_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [ 1 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from functools import partial\n",
    "\n",
    "def make_model_1():\n",
    "    Dense = partial(layers.Dense, # 필요한 레이어를 사전 정의하는 함수\n",
    "               activation='elu',\n",
    "               kernel_initializer='he_normal',\n",
    "               )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(28*28,)),\n",
    "        Dense(300),\n",
    "        Dense(100),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2508 - accuracy: 0.9230 - val_loss: 0.1678 - val_accuracy: 0.9503\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1154 - accuracy: 0.9641 - val_loss: 0.1186 - val_accuracy: 0.9651\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0772 - accuracy: 0.9756 - val_loss: 0.1083 - val_accuracy: 0.9695\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0599 - accuracy: 0.9809 - val_loss: 0.0963 - val_accuracy: 0.9722\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 0.0816 - val_accuracy: 0.9779\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.0981 - val_accuracy: 0.9723\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.1247 - val_accuracy: 0.9696\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.1025 - val_accuracy: 0.9743\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.1136 - val_accuracy: 0.9765\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.1385 - val_accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21198d59790>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 생성\n",
    "model=make_model_1()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('results_11-2/model_1.h5', save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=10,\n",
    "          callbacks=[model_checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0847 - accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.models.load_model('results_11-2/model_1.h5')\n",
    "m1_test = model_1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 97.64 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_1.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "print(\"정확도:\", sum(y_pred_class == y_test)/10000*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [ 2 ] l1 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://m.blog.naver.com/PostView.nhn?blogId=sky3000v&logNo=221536661344&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "\n",
    "* L1 규제: L1의 경우에는 가중치의 크기에 상관없이 상수값을 뺍니다. 이는 대체적으로 불필요한 가중치의 수치를 0으로 만들도록 하는 방향으로 적용됩니다. 즉, 중요한 가중치만을 취하기 때문에 sparse feature에 대한 모델을 구성하는데 적합합니다.\n",
    "\n",
    "\n",
    "* L2 규제: L2의 경우에는 가중치의 값을 이용합니다. 어느 정도 튀는 값에 대해 대응할 수 있다는 소리죠. 따라서, 이상치나 노이즈가 있는 데이터에 대한 학습을 진행할 때 사용하면 좋습니다. 특히 선형 모델의 일반화에 좋다고 합니다.     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "##### Glorot Initialization 또는 Xavier Initialization\n",
    "\n",
    "<br>\n",
    "\n",
    "* 활성화 함수가 없거나, 하이퍼볼릭 탄젠트(tanh, hyperbolic tangent), 로지스틱(Logistic Sigmoid), 소프트맥스(SoftMax) 함수 등에는,\n",
    "\n",
    "\n",
    "* $fan_{avg} = \\frac{(fan_{in}+fan_{out})}{2} $ 일 때,\n",
    "\n",
    "\n",
    "* 평균이 0, 분산이 $\\sigma^{2} = \\frac{1}{fan_{out}}$ 인 정규 분포 (normal dist)\n",
    "\n",
    "\n",
    "* $r = \\sqrt{\\frac{3}{fan_{avg}}}$ 일때, $-r$과 $+r$ 사이의 균등 분포 (uniform dist)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from functools import partial\n",
    "\n",
    "def make_model_2():\n",
    "    RegularizedDense = partial(layers.Dense, # 필요한 레이어를 사전 정의하는 함수\n",
    "               activation='elu',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=tf.keras.regularizers.l1(0.01) # l1 norm 사용\n",
    "               )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(28*28,)),\n",
    "        RegularizedDense(300),\n",
    "        RegularizedDense(100),\n",
    "        layers.Dense(10, activation='softmax', \n",
    "                    kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 콜백 ModelCheckpoint의 저장 이름을 **2_model.h5**로 바꿉니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 4.7989 - accuracy: 0.7917 - val_loss: 1.4072 - val_accuracy: 0.8572\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 1.3619 - accuracy: 0.8533 - val_loss: 1.2760 - val_accuracy: 0.8714\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.2861 - accuracy: 0.8644 - val_loss: 1.2486 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.2478 - accuracy: 0.8703 - val_loss: 1.1935 - val_accuracy: 0.8844\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.2108 - accuracy: 0.8737 - val_loss: 1.1890 - val_accuracy: 0.8812\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1881 - accuracy: 0.8755 - val_loss: 1.1716 - val_accuracy: 0.8770\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1688 - accuracy: 0.8766 - val_loss: 1.1255 - val_accuracy: 0.8821\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1530 - accuracy: 0.8773 - val_loss: 1.1240 - val_accuracy: 0.8764\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1382 - accuracy: 0.8783 - val_loss: 1.1053 - val_accuracy: 0.8836\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1303 - accuracy: 0.8781 - val_loss: 1.1019 - val_accuracy: 0.8838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x211807a8a00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 생성\n",
    "model=make_model_2()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('results_11-2/model_2.h5', \n",
    "                                                         save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=10,\n",
    "          callbacks=[model_checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1000 - accuracy: 0.8829\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.models.load_model('results_11-2/model_2.h5')\n",
    "m2_test = model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 88.29 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_2.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "print(\"정확도:\", sum(y_pred_class == y_test)/10000*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [  3 ]  l2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from functools import partial\n",
    "\n",
    "def make_model_3():\n",
    "    RegularizedDense = partial(layers.Dense, # 필요한 레이어를 사전 정의하는 함수\n",
    "               activation='elu',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(0.01) # l2 norm 사용\n",
    "               )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(28*28,)),\n",
    "        RegularizedDense(300),\n",
    "        RegularizedDense(100),\n",
    "        layers.Dense(10, activation='softmax', \n",
    "                    kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 콜백 ModelCheckpoint의 저장 이름을 **3_model.h5**로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 1.1257 - accuracy: 0.8742 - val_loss: 0.5747 - val_accuracy: 0.8999\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5536 - accuracy: 0.9003 - val_loss: 0.4967 - val_accuracy: 0.9153\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4939 - accuracy: 0.9115 - val_loss: 0.4509 - val_accuracy: 0.9225\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4637 - accuracy: 0.9179 - val_loss: 0.4353 - val_accuracy: 0.9252\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4486 - accuracy: 0.9202 - val_loss: 0.4200 - val_accuracy: 0.9308\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4289 - accuracy: 0.9249 - val_loss: 0.4093 - val_accuracy: 0.9330\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4190 - accuracy: 0.9273 - val_loss: 0.4124 - val_accuracy: 0.9313\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4135 - accuracy: 0.9255 - val_loss: 0.4195 - val_accuracy: 0.9267\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4108 - accuracy: 0.9284 - val_loss: 0.4225 - val_accuracy: 0.9274\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4015 - accuracy: 0.9291 - val_loss: 0.3677 - val_accuracy: 0.9424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21195ad4520>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 생성\n",
    "model=make_model_3()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('results_11-2/model_3.h5', \n",
    "                                                         save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=10,\n",
    "          callbacks=[model_checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.9403\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.models.load_model('results_11-2/model_3.h5')\n",
    "m3_test = model_3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 94.03 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_3.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "print(\"정확도:\", sum(y_pred_class == y_test)/10000*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [  4 ] DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from functools import partial\n",
    "\n",
    "def make_model_4():\n",
    "    Dense = partial(layers.Dense, # 필요한 레이어를 사전 정의하는 함수\n",
    "               activation='elu',\n",
    "               kernel_initializer='he_normal',\n",
    "    #           kernel_regularizer=tf.keras.regularizers.l2(0.01) \n",
    "               )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(28*28,)),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        Dense(300),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        Dense(100),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(10, activation='softmax', \n",
    "                    kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 콜백 ModelCheckpoint의 저장 이름을 **4_model.h5**로 바꿉니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3678 - accuracy: 0.8866 - val_loss: 0.1528 - val_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2016 - accuracy: 0.9377 - val_loss: 0.1207 - val_accuracy: 0.9622\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1630 - accuracy: 0.9489 - val_loss: 0.0985 - val_accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1390 - accuracy: 0.9563 - val_loss: 0.0960 - val_accuracy: 0.9709\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1235 - accuracy: 0.9605 - val_loss: 0.0975 - val_accuracy: 0.9715\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1121 - accuracy: 0.9652 - val_loss: 0.0873 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1051 - accuracy: 0.9665 - val_loss: 0.0822 - val_accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0985 - accuracy: 0.9695 - val_loss: 0.0766 - val_accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0912 - accuracy: 0.9710 - val_loss: 0.0781 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0842 - accuracy: 0.9726 - val_loss: 0.0860 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21196207940>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 생성\n",
    "model=make_model_4()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('results_11-2/model_4.h5', \n",
    "                                                         save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=10,\n",
    "          callbacks=[model_checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "model_4 = tf.keras.models.load_model('results_11-2/model_4.h5')\n",
    "m4_test = model_4.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 97.48 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_4.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "print(\"정확도:\", sum(y_pred_class == y_test)/10000*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 5 ]\n",
    "\n",
    "* 지금까지 만든 4가지 모델을 불러오고 평가해 봅니다.\n",
    "* **tf.keras.models.load_model( )**을 통해 모델을 불러올 수 있습니다.\n",
    "* **model.evaluate( )**를 통해 모든 모델을 평가해 봅니다.\n",
    "* 불러오기 전에 아래 셀에서 각 모델의 특징을 간단히 메모하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model_1: Adam, Dense(Elu & He_normal)\n",
    "* model_2: L1 Norm (l1=0.01), Adam, Dense(Elu & He_normal), Output layer(softmax & glorot_uniform)\n",
    "* model_3: L2 Norm (l2=0.01), Adam, Dense(Elu & He_normal), Output layer(softmax & glorot_uniform)\n",
    "* model_4: DropOut (rate=0.2),  Adam, Dense(Elu & He_normal), Output layer(softmax & glorot_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model_1 = tf.keras.models.load_model('results_11-2/model_1.h5')\n",
    "model_2 = tf.keras.models.load_model('results_11-2/model_2.h5')\n",
    "model_3 = tf.keras.models.load_model('results_11-2/model_3.h5')\n",
    "model_4 = tf.keras.models.load_model('results_11-2/model_4.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9764\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1000 - accuracy: 0.8829\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.9403\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.97 - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9748\n",
      "m1: [0.08466541767120361, 0.9764000177383423] \n",
      " m2: [1.099966049194336, 0.8828999996185303] \n",
      " m3: [0.37132662534713745, 0.9402999877929688] \n",
      " m4: [0.07503607869148254, 0.9747999906539917]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "m1_test = model_1.evaluate(x_test, y_test)\n",
    "m2_test = model_2.evaluate(x_test, y_test)\n",
    "m3_test = model_3.evaluate(x_test, y_test)\n",
    "m4_test = model_4.evaluate(x_test, y_test)\n",
    "print(\"m1:\", m1_test, \"\\n\",\n",
    "      \"m2:\", m2_test, \"\\n\",\n",
    "      \"m3:\", m3_test, \"\\n\",\n",
    "      \"m4:\", m4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
